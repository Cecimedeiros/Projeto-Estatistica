{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db24c14",
   "metadata": {},
   "source": [
    "## Análise de e-commerce brasileiro - Olist Dataset\n",
    "### Limpeza e preparação de dados\n",
    "Equipe: André Braga & Cecília Medeiros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad2203",
   "metadata": {},
   "source": [
    "Imports e Configuração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4cb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536605a",
   "metadata": {},
   "source": [
    "Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b9701",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m orders = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/olist_orders_dataset.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m order_items = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/olist_order_items_dataset.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m order_payments = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/olist_order_payments_dataset.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ANÁLISE DE E-COMMERCE BRASILEIRO - OLIST DATASET\")\n",
    "print(\"Equipe Cedré\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(\"1. CARREGANDO DADOS...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "orders = pd.read_csv('data/olist_orders_dataset.csv')\n",
    "order_items = pd.read_csv('data/olist_order_items_dataset.csv')\n",
    "order_payments = pd.read_csv('data/olist_order_payments_dataset.csv')\n",
    "customers = pd.read_csv('data/olist_customers_dataset.csv')\n",
    "products = pd.read_csv('data/olist_products_dataset.csv')\n",
    "sellers = pd.read_csv('data/olist_sellers_dataset.csv')\n",
    "category_translation = pd.read_csv('data/product_category_name_translation.csv')\n",
    "\n",
    "print(f\"✓ Orders: {orders.shape[0]:,} registros, {orders.shape[1]} colunas\")\n",
    "print(f\"✓ Order Items: {order_items.shape[0]:,} registros, {order_items.shape[1]} colunas\")\n",
    "print(f\"✓ Order Payments: {order_payments.shape[0]:,} registros, {order_payments.shape[1]} colunas\")\n",
    "print(f\"✓ Customers: {customers.shape[0]:,} registros, {customers.shape[1]} colunas\")\n",
    "print(f\"✓ Products: {products.shape[0]:,} registros, {products.shape[1]} colunas\")\n",
    "print(f\"✓ Sellers: {sellers.shape[0]:,} registros, {sellers.shape[1]} colunas\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed30d8b",
   "metadata": {},
   "source": [
    "Análise de qualidade de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc4eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. ANÁLISE DE QUALIDADE DOS DADOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2.1. Valores Ausentes (Orders):\n",
      "                               Missing  Percentage\n",
      "order_approved_at                  160        0.16\n",
      "order_delivered_carrier_date      1783        1.79\n",
      "order_delivered_customer_date     2965        2.98\n",
      "\n",
      "2.2. Valores Ausentes (Order Items):\n",
      "Total missing: 0\n",
      "\n",
      "2.3. Duplicatas:\n",
      "Orders duplicados: 0\n",
      "Customers duplicados: 0\n",
      "Products duplicados: 0\n",
      "\n",
      "3. CONVERSÃO DE TIPOS DE DADOS\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Convertido: order_purchase_timestamp\n",
      "✓ Convertido: order_approved_at\n",
      "✓ Convertido: order_delivered_carrier_date\n",
      "✓ Convertido: order_delivered_customer_date\n",
      "✓ Convertido: order_estimated_delivery_date\n",
      "✓ Convertido: shipping_limit_date\n",
      "\n",
      "4. TRATAMENTO DE STRINGS\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"2. ANÁLISE DE QUALIDADE DOS DADOS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\n2.1. Valores Ausentes (Orders):\")\n",
    "missing_orders = orders.isnull().sum()\n",
    "missing_pct = (missing_orders / len(orders) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing': missing_orders,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing'] > 0])\n",
    "\n",
    "print(\"\\n2.2. Valores Ausentes (Order Items):\")\n",
    "missing_items = order_items.isnull().sum()\n",
    "print(f\"Total missing: {missing_items.sum()}\")\n",
    "\n",
    "print(\"\\n2.3. Duplicatas:\")\n",
    "print(f\"Orders duplicados: {orders.duplicated(subset='order_id').sum()}\")\n",
    "print(f\"Customers duplicados: {customers.duplicated(subset='customer_id').sum()}\")\n",
    "print(f\"Products duplicados: {products.duplicated(subset='product_id').sum()}\")\n",
    "print()\n",
    "\n",
    "print(\"3. CONVERSÃO DE TIPOS DE DADOS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "date_columns = [\n",
    "    'order_purchase_timestamp',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_estimated_delivery_date'\n",
    "]\n",
    "\n",
    "for col in date_columns:\n",
    "    orders[col] = pd.to_datetime(orders[col], errors='coerce')\n",
    "    print(f\"✓ Convertido: {col}\")\n",
    "\n",
    "order_items['shipping_limit_date'] = pd.to_datetime(order_items['shipping_limit_date'], errors='coerce')\n",
    "print(f\"✓ Convertido: shipping_limit_date\")\n",
    "print()\n",
    "\n",
    "print(\"4. TRATAMENTO DE STRINGS\")\n",
    "print(\"-\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997e14f",
   "metadata": {},
   "source": [
    "Trimming e padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2516d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings padronizadas (trim, case)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders['order_status'] = orders['order_status'].str.strip().str.lower()\n",
    "order_payments['payment_type'] = order_payments['payment_type'].str.strip().str.lower()\n",
    "customers['customer_state'] = customers['customer_state'].str.strip().str.upper()\n",
    "sellers['seller_state'] = sellers['seller_state'].str.strip().str.upper()\n",
    "\n",
    "print(\"Strings padronizadas (trim, case)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f4f82",
   "metadata": {},
   "source": [
    "Merge de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a87d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. MERGE DOS DATASETS\n",
      "--------------------------------------------------------------------------------\n",
      "Merged orders + order_items: 113,425 registros\n",
      "Merged payments: 113,425 registros\n",
      "Merged customers: 113,425 registros\n",
      "Merged products: 113,425 registros\n",
      "Merged sellers: 113,425 registros\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"5. MERGE DOS DATASETS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# orders + order_items + order_payments\n",
    "df = orders.merge(order_items, on='order_id', how='left')\n",
    "print(f\"Merged orders + order_items: {df.shape[0]:,} registros\")\n",
    "\n",
    "payments_agg = order_payments.groupby('order_id').agg({\n",
    "    'payment_type': lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0],\n",
    "    'payment_value': 'sum',\n",
    "    'payment_installments': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "df = df.merge(payments_agg, on='order_id', how='left')\n",
    "print(f\"Merged payments: {df.shape[0]:,} registros\")\n",
    "\n",
    "df = df.merge(customers[['customer_id', 'customer_state', 'customer_city']], \n",
    "              on='customer_id', how='left')\n",
    "print(f\"Merged customers: {df.shape[0]:,} registros\")\n",
    "\n",
    "products_merged = products.merge(category_translation, \n",
    "                                  left_on='product_category_name',\n",
    "                                  right_on='product_category_name',\n",
    "                                  how='left')\n",
    "df = df.merge(products_merged[['product_id', 'product_category_name_english']], \n",
    "              on='product_id', how='left')\n",
    "print(f\"Merged products: {df.shape[0]:,} registros\")\n",
    "\n",
    "df = df.merge(sellers[['seller_id', 'seller_state', 'seller_city']], \n",
    "              on='seller_id', how='left')\n",
    "print(f\"Merged sellers: {df.shape[0]:,} registros\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5333e50",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2900581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. FEATURE ENGINEERING\n",
      "--------------------------------------------------------------------------------\n",
      "Criadas: subtotal, freight, total\n",
      "Criadas: delivery_lead_time, delivery_delay_days, is_late\n",
      "Criadas: is_confirmed, is_canceled\n",
      "Criada: freight_share\n",
      "Criadas: order_month, order_year, order_month_num, order_weekday, order_hour\n",
      "Criada: customer_region\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"6. FEATURE ENGINEERING\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# 6.1. Métricas de receita\n",
    "df['subtotal'] = df['price']\n",
    "df['freight'] = df['freight_value']\n",
    "df['total'] = df['price'] + df['freight_value']\n",
    "\n",
    "print(\"Criadas: subtotal, freight, total\")\n",
    "\n",
    "# 6.2. Métricas de entrega\n",
    "df['delivery_lead_time'] = (df['order_delivered_customer_date'] - \n",
    "                             df['order_purchase_timestamp']).dt.days\n",
    "\n",
    "df['delivery_delay_days'] = (df['order_delivered_customer_date'] - \n",
    "                               df['order_estimated_delivery_date']).dt.days\n",
    "\n",
    "df['is_late'] = (df['delivery_delay_days'] > 0).astype(int)\n",
    "\n",
    "print(\"Criadas: delivery_lead_time, delivery_delay_days, is_late\")\n",
    "\n",
    "# 6.3. Status de confirmação\n",
    "df['is_confirmed'] = (df['order_status'] == 'delivered').astype(int)\n",
    "df['is_canceled'] = (df['order_status'] == 'canceled').astype(int)\n",
    "\n",
    "print(\"Criadas: is_confirmed, is_canceled\")\n",
    "\n",
    "# 6.4. Take-rate de frete\n",
    "df['freight_share'] = df['freight'] / df['total']\n",
    "df['freight_share'] = df['freight_share'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print(\"Criada: freight_share\")\n",
    "\n",
    "# 6.5. Temporal features\n",
    "df['order_month'] = df['order_purchase_timestamp'].dt.to_period('M')\n",
    "df['order_year'] = df['order_purchase_timestamp'].dt.year\n",
    "df['order_month_num'] = df['order_purchase_timestamp'].dt.month\n",
    "df['order_weekday'] = df['order_purchase_timestamp'].dt.dayofweek\n",
    "df['order_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "\n",
    "print(\"Criadas: order_month, order_year, order_month_num, order_weekday, order_hour\")\n",
    "\n",
    "# 6.6. Região geográfica (simplificada)\n",
    "regiao_map = {\n",
    "    'SP': 'Sudeste', 'RJ': 'Sudeste', 'MG': 'Sudeste', 'ES': 'Sudeste',\n",
    "    'PR': 'Sul', 'SC': 'Sul', 'RS': 'Sul',\n",
    "    'BA': 'Nordeste', 'PE': 'Nordeste', 'CE': 'Nordeste', 'MA': 'Nordeste',\n",
    "    'RN': 'Nordeste', 'PB': 'Nordeste', 'SE': 'Nordeste', 'AL': 'Nordeste', 'PI': 'Nordeste',\n",
    "    'GO': 'Centro-Oeste', 'MT': 'Centro-Oeste', 'MS': 'Centro-Oeste', 'DF': 'Centro-Oeste',\n",
    "    'AM': 'Norte', 'PA': 'Norte', 'RO': 'Norte', 'AC': 'Norte', 'RR': 'Norte', \n",
    "    'AP': 'Norte', 'TO': 'Norte'\n",
    "}\n",
    "df['customer_region'] = df['customer_state'].map(regiao_map)\n",
    "\n",
    "print(\"Criada: customer_region\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0089696",
   "metadata": {},
   "source": [
    "Tratamento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c78730d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. IDENTIFICAÇÃO DE OUTLIERS\n",
      "--------------------------------------------------------------------------------\n",
      "total: 8,253 outliers (7.33%) | Range: [-98.86, 312.01]\n",
      "freight: 12,134 outliers (10.77%) | Range: [0.98, 33.25]\n",
      "delivery_lead_time: 5,560 outliers (5.05%) | Range: [-7.50, 28.50]\n",
      "payment_value: 9,285 outliers (8.19%) | Range: [-128.84, 389.88]\n",
      "\n",
      "Outliers identificados, mas mantidos para análise completa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"7. IDENTIFICAÇÃO DE OUTLIERS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \n",
    "    \"\"\"\n",
    "        Detecta outliers usando método IQR\n",
    "    \"\"\"\n",
    "\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((data[column] < lower_bound) | (data[column] > upper_bound)).sum()\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Análise de outliers em variáveis chave\n",
    "outlier_cols = ['total', 'freight', 'delivery_lead_time', 'payment_value']\n",
    "for col in outlier_cols:\n",
    "    if col in df.columns:\n",
    "        n_outliers, lower, upper = detect_outliers_iqr(df.dropna(subset=[col]), col)\n",
    "        pct = (n_outliers / df[col].notna().sum() * 100)\n",
    "        print(f\"{col}: {n_outliers:,} outliers ({pct:.2f}%) | Range: [{lower:.2f}, {upper:.2f}]\")\n",
    "\n",
    "print(\"\\nOutliers identificados, mas mantidos para análise completa\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f948c7",
   "metadata": {},
   "source": [
    "Filtros e limpeza final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4cded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. FILTROS E LIMPEZA FINAL\n",
      "--------------------------------------------------------------------------------\n",
      "Filtrado por status válido: 113,425 → 112,807\n",
      "Removidos valores negativos: 112,640 registros\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"8. FILTROS E LIMPEZA FINAL\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Remover pedidos sem informações críticas\n",
    "df_clean = df.copy()\n",
    "initial_count = len(df_clean)\n",
    "\n",
    "# Manter apenas pedidos com status válido\n",
    "valid_status = ['delivered', 'canceled', 'shipped', 'invoiced', 'processing']\n",
    "df_clean = df_clean[df_clean['order_status'].isin(valid_status)]\n",
    "print(f\"Filtrado por status válido: {initial_count:,} → {len(df_clean):,}\")\n",
    "\n",
    "# Remover registros com valores negativos\n",
    "df_clean = df_clean[df_clean['price'] >= 0]\n",
    "df_clean = df_clean[df_clean['freight_value'] >= 0]\n",
    "print(f\"Removidos valores negativos: {len(df_clean):,} registros\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205af59",
   "metadata": {},
   "source": [
    "Salvar dados limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c5c388e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9. SALVANDO DADOS LIMPOS\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Arquivo salvo: data_cleaned.csv (112,640 registros)\n",
      "✓ Arquivo salvo: orders_aggregated.csv (98,658 pedidos únicos)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"9. SALVANDO DADOS LIMPOS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df_clean.to_csv('data_cleaned.csv', index=False)\n",
    "print(f\"✓ Arquivo salvo: data_cleaned.csv ({len(df_clean):,} registros)\")\n",
    "\n",
    "# Salvar também versão agregada por pedido\n",
    "df_orders = df_clean.groupby('order_id').agg({\n",
    "    'customer_id': 'first',\n",
    "    'order_status': 'first',\n",
    "    'order_purchase_timestamp': 'first',\n",
    "    'order_delivered_customer_date': 'first',\n",
    "    'order_estimated_delivery_date': 'first',\n",
    "    'payment_type': 'first',\n",
    "    'payment_value': 'first',\n",
    "    'payment_installments': 'first',\n",
    "    'customer_state': 'first',\n",
    "    'customer_region': 'first',\n",
    "    'total': 'sum',\n",
    "    'freight': 'sum',\n",
    "    'subtotal': 'sum',\n",
    "    'delivery_lead_time': 'first',\n",
    "    'delivery_delay_days': 'first',\n",
    "    'is_late': 'first',\n",
    "    'is_confirmed': 'first',\n",
    "    'is_canceled': 'first',\n",
    "    'order_month': 'first',\n",
    "    'order_year': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "df_orders.to_csv('orders_aggregated.csv', index=False)\n",
    "print(f\"✓ Arquivo salvo: orders_aggregated.csv ({len(df_orders):,} pedidos únicos)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608ca34",
   "metadata": {},
   "source": [
    "Resumo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "461fd0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. RESUMO FINAL\n",
      "================================================================================\n",
      "Dataset original: 113,425 registros\n",
      "Dataset limpo: 112,640 registros\n",
      "Pedidos únicos: 98,658\n",
      "Período: 2016-09-04 21:15:19 a 2018-09-03 09:06:57\n",
      "Estados: 27\n",
      "Categorias: 71\n",
      "================================================================================\n",
      "✓ LIMPEZA E PREPARAÇÃO CONCLUÍDA COM SUCESSO!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"10. RESUMO FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dataset original: {initial_count:,} registros\")\n",
    "print(f\"Dataset limpo: {len(df_clean):,} registros\")\n",
    "print(f\"Pedidos únicos: {len(df_orders):,}\")\n",
    "print(f\"Período: {df_clean['order_purchase_timestamp'].min()} a {df_clean['order_purchase_timestamp'].max()}\")\n",
    "print(f\"Estados: {df_clean['customer_state'].nunique()}\")\n",
    "print(f\"Categorias: {df_clean['product_category_name_english'].nunique()}\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ LIMPEZA E PREPARAÇÃO CONCLUÍDA COM SUCESSO!\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
